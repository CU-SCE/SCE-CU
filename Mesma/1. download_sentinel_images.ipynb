{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82702dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/anaconda3/lib/python3.12/site-packages (1.35.24)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.24 in /opt/anaconda3/lib/python3.12/site-packages (from boto3) (1.35.24)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/lib/python3.12/site-packages (from botocore<1.36.0,>=1.35.24->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/anaconda3/lib/python3.12/site-packages (from botocore<1.36.0,>=1.35.24->boto3) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.24->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting shapely\n",
      "  Downloading shapely-2.0.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/anaconda3/lib/python3.12/site-packages (from shapely) (1.26.4)\n",
      "Downloading shapely-2.0.6-cp312-cp312-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely\n",
      "Successfully installed shapely-2.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting geojson\n",
      "  Downloading geojson-3.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Downloading geojson-3.1.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: geojson\n",
      "Successfully installed geojson-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: botocore in /opt/anaconda3/lib/python3.12/site-packages (1.35.24)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from botocore) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/lib/python3.12/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/anaconda3/lib/python3.12/site-packages (from botocore) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3\n",
    "%pip install numpy\n",
    "%pip install shapely\n",
    "%pip install geojson\n",
    "%pip install botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2ce6a-f70f-46d1-a1c8-689dd3dfd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes to import, clean, and process Sentinel-2 data using VSI and AWS were written by Lilly Jones and Erick Verleye; edited by Ty Tuff, pseudocode by Cibele Amaral. \n",
    "\n",
    "#imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "from argparse import Namespace\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Tuple, Union\n",
    "import boto3\n",
    "import geojson\n",
    "import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "import botocore\n",
    "from collections import defaultdict\n",
    "from download_task import download_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_name = \"sce.sentinel2\" #Create bucket if not created\n",
    "s3_bucket_prefix = \"july_2024_input\" #Create bucket prefix if not created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec95031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the temporary credentials before running the below code\n",
    "\n",
    "def get_aws_creds():\n",
    "    return {'aws_access_key_id': 'ASIA33KJUBNFSFQ3SIOV', 'aws_secret_access_key': '6gAh9kmzTkaeDnABZ9D6qLghHAm8AY+OFt4tE1FP', 'aws_session_token': 'FwoGZXIvYXdzEKP//////////wEaDA0dLf2AyEeACOBg2iLZAgAXbcjCMgLXxaBoXg+1/OTzp5fq1b4D7jfc3XztAgFr5UlFZqss7+FtE7rAb+F42wtxyQGhfXv6zimTgdjV3+WhOmw7SxFdtrW9K4jjyjprX3JO41MagwM0+ZSvNN6bqMA73olBET1MrZFTeBfmJnIHgKufiei5pMRmqthJTvdId4REml03BzxcAjnJXf7/JDnnKEIopNHnpuR5IafCo2oSO+3KiXb9Qyfmiqaex9uNqS6k+ly5b7Q7HR6j9vdpFXuHamz4fPzQbeB8FthvB08yIf+3fByCwmAm4q4o4ZdXro14rr0uyBzPLB7lzKVou5hRIO623x3isIkLVwEFZiSm51TpLgF2yCVJzU8CWYdGSgeX9GEZNKw1J/mjaJqgPf4TJEA3tV2z8cHCGcUcuvYjbeYER+a7x2bri6fCI7kDZYLlW0OOhzhp+NMZcHBbLC+536ZUvnAnpSjkuam5BjIzXBQKgA3++i63xjpf5txyuSnQc92hVS19T58bYu4PKYNQfLiN6sBmZL9ek6AsLrzYDRJ2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636802b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3',**get_aws_creds())\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "746d4414-7342-4ae7-93f9-3493d05086f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original AWS code by Erick Verleye, ESIIL Software Developer 2023-08-08, lightly edited by Lilly Jones for SCE project\n",
    "# Code downloads Sentinel Level-1 C data from S3 with Python for a given latitude, longitude, and date range.\n",
    "# An AWS account is needed and will be charged (a small amount) for any data downloaded.\n",
    "\n",
    "# Use boto3 to create a connection to the AWS account. Initialization of the boto3.session object changes depending on the environment you are running this code in:\n",
    "\n",
    "# Using the AWS CLI from a personal computer to log in, the profile name will typically be default.\n",
    "# Using a federated access login, the profile name will typically be the name of the software.\n",
    "# Using S3 configured IAM profile, no profile name is required.\n",
    "# Each of these arguments, if applicable, can be found in the aws credentials file typically found at ~/.aws/credentials\n",
    "\n",
    "# session = boto3.Session(profile_name='saml')\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "# Define constants\n",
    "SENTINEL_2_BUCKET_NAME = 'sentinel-s2-l1c'  # Name of the s3 bucket on AWS hosting the sentinel-2 data\n",
    "\n",
    "\n",
    "# find_overlapping_mgrs Sentinel-2 data is organized depending on which Military Grid Reference System (MGRS) square that it belongs to. This function converts a bounding box defined in    # lat/lon as [min_lon, min_lat, max_lon, max_lat] to the military grid squares that is overlaps. More information on # # the MGRS can be found at                                                       # https://www.maptools.com/tutorials/mgrs/quick_guide. NOTE: You will have to download the mgrs_lookup.geojson file from # # # # # https://github.com/CU-ESIIL/data-                        # library/blob/main/docs/remote_sensing/sentinel2_aws/mgrs_lookup.geojson and place it into the working directory that # # this code is being run from.\n",
    "\n",
    "def find_overlapping_mgrs(bounds: List[float]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Files in the Sinergise Sentinel2 S3 bucket are organized by which military grid they overlap. Thus, the\n",
    "    military grids that overlap the input bounding box defined in lat / lon must be found. A lookup table that\n",
    "    includes each grid name and its geometry is used to find the overlapping grids.\n",
    "    Args:\n",
    "        bounds (list): Bounding box definition as [min_lon, min_lat, max_lon, max_lat]\n",
    "    \"\"\"\n",
    "    print('Finding overlapping tiles... ')\n",
    "    input_bounds = Polygon([(bounds[0], bounds[1]), (bounds[2], bounds[1]), (bounds[2], bounds[3]),\n",
    "                            (bounds[0], bounds[3]), (bounds[0], bounds[1])])\n",
    "    with open('california-100km-mgrs.geojson', 'r') as f:\n",
    "        ft = geojson.load(f)\n",
    "        return [i['properties']['GRID1MIL'] + i['properties']['GRID100K'] for i in ft[1:] if\n",
    "                input_bounds.intersects(Polygon(i['geometry']['coordinates'][0]))]\n",
    "\n",
    "# find_available_files finds the set of available files in the s3 bucket given a date range, lat/lon bounds, and list of bands.\n",
    "\n",
    "def find_available_files(s3_client, bounds: List[float], start_date: datetime, end_date: datetime,\n",
    "                         bands: List[str]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Given a bounding box and start / end date, finds which files are available on the bucket and\n",
    "    meet the search criteria\n",
    "    Args:\n",
    "        bounds (list): Lower left and top right corner of bounding box defined in\n",
    "        lat / lon [min_lon, min_lat, max_lon, max_lat]\n",
    "        start_date (str): Beginning of requested data creation date YYYY-MM-DD\n",
    "        end_date (str): End of requested data creation date YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    date_paths = []\n",
    "    ref_date = start_date\n",
    "    while ref_date <= end_date:\n",
    "        tt = ref_date.timetuple()\n",
    "        date_paths.append(f'/{tt.tm_year}/{tt.tm_mon}/{tt.tm_mday}/')\n",
    "        ref_date = ref_date + timedelta(days=1)\n",
    "\n",
    "    info = []\n",
    "    # mgrs_grids = [\"11SKU\", \"11SMT\",\"11SLU\",\"11SLV\",\"11SNT\",'10SGD', '10SGE', '10SGF', '11SMS', '11SNS', '11SPS', '11SQS', '11SKT']\n",
    "    # mgrs_grids = ['11SMT', '11SNT', '11SPT', '11SQT', '11SKU', '11SLU', '11SMU', '11SNU', '11SPU', '11SQU', '11SKV', '11SLV']\n",
    "    # mgrs_grids = ['11SNV', '11SPV', '11SKA', '11SLA', '11SMA', '11SNA', '11SKB', '11SLB', '11SMB', '11SKC', '11SLC', '11SLT','11SMV']\n",
    "    mgrs_grids = [\"11SKU\", \"11SMT\",\"11SLU\",\"11SLV\",\"11SNT\",'10SGD', '10SGE', '10SGF', '11SMS', '11SNS', '11SPS', '11SQS', '11SKT','11SMT', '11SNT', '11SPT', '11SQT', '11SKU', '11SLU', '11SMU', '11SNU', '11SPU', '11SQU', '11SKV', '11SLV','11SNV', '11SPV', '11SKA', '11SLA', '11SMA', '11SNA', '11SKB', '11SLB', '11SMB', '11SKC', '11SLC', '11SLT','11SMV']\n",
    "    i=0\n",
    "    for grid_string in mgrs_grids:\n",
    "        i+=1\n",
    "        utm_code = grid_string[:2]\n",
    "        latitude_band = grid_string[2]\n",
    "        square = grid_string[3:5]\n",
    "        grid = f'tiles/{utm_code}/{latitude_band}/{square}'\n",
    "        response = s3_client.list_objects_v2(\n",
    "            Bucket=SENTINEL_2_BUCKET_NAME,\n",
    "            Prefix=grid + '/',\n",
    "            MaxKeys=300,\n",
    "            RequestPayer='requester'\n",
    "        )\n",
    "        if 'Contents' not in list(response.keys()):\n",
    "            continue\n",
    "\n",
    "        for date in date_paths:\n",
    "            response = s3_client.list_objects_v2(\n",
    "                Bucket=SENTINEL_2_BUCKET_NAME,\n",
    "                Prefix=grid + date + '0/',  # '0/' is for the sequence, which in most cases will be 0\n",
    "                MaxKeys=100,\n",
    "                RequestPayer='requester'\n",
    "            )\n",
    "            if 'Contents' in list(response.keys()):\n",
    "#                 print([v['Key'] for v in response['Contents']])\n",
    "                info += [\n",
    "                    (v['Key'], v['Size']) for v in response['Contents'] \n",
    "                ]\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e1fbc-fadd-42a9-9dc3-73a0968d7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is designed to download the files in parallel, so a download_task function is defined as well. \n",
    "# Note that multiprocessing will not work as implemented here in iPython (Jupyter # # notebooks, etc.) and so that block of code is commented out. \n",
    "# If you are running this in a different environment and would like to download in parallel, un-comment this block and comment the sequential block below.\n",
    "\n",
    "\n",
    "def download_task(namespace: Namespace) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a single file from the indicated s3 bucket. This function is intended to be spawned in parallel from the\n",
    "    parent process.\n",
    "    Args:\n",
    "        namespace (Namespace): Contains the bucket name, s3 file name, and destination required for s3 download request.\n",
    "        Each value in the namespace must be a pickle-izable type (i.e. str).\n",
    "    \"\"\"\n",
    "#     session = boto3.Session(profile_name=namespace.profile_name)\n",
    "    session = boto3.Session()\n",
    "    s3 = session.client('s3',**get_aws_creds())\n",
    "    s3.download_file(namespace.bucket_name, namespace.available_file,\n",
    "                     namespace.dest,\n",
    "                     ExtraArgs={'RequestPayer': 'requester'}\n",
    "                     )\n",
    "    file_name = namespace.dest.split(\"\\\\\")[-1]\n",
    "    file_downloaded_destination =file_name\n",
    "    upload_file(file_downloaded_destination,s3_bucket_name, '{s3_bucket_prefix}/{}'.format(file_name))\n",
    "    os.remove(file_downloaded_destination)\n",
    "\n",
    "\n",
    "def download(session, bounds: List[float], start_date: datetime, end_date: datetime,\n",
    "             bands: List[float], buffer: float = None) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a list of .jp2 files from the Sinergise Sentinel2 LC1 bucket given a bounding box defined in lat/long, a buffer in meters, and a start and end date. Only Bands 2-4 are requested.\n",
    "     Args:\n",
    "         bounds (list): Bounding box defined in lat / lon [min_lon, min_lat, max_lon, max_lat]\n",
    "         buffer (float): Amount by which to extend the bounding box by, in meters\n",
    "         start_date (str): Beginning of requested data creation date YYYY-MM-DD\n",
    "         end_date (str): End of requested data creation date YYYY-MM-DD\n",
    "         bands (list): The bands to download for each file. Ex. ['B02', 'B03', 'B04', 'B08'] for R, G, B, and\n",
    "         near wave IR, respectively\n",
    "         out_dir (str): Path to directory where downloaded files will be written to\n",
    "    \"\"\"\n",
    "    # Convert the buffer from meters to degrees lat/long at the equator\n",
    "    if buffer is not None:\n",
    "        buffer /= 111000\n",
    "\n",
    "        # Adjust the bounding box to include the buffer (subtract from min lat/long values, add to max lat/long values)\n",
    "        bounds[0] -= buffer\n",
    "        bounds[1] -= buffer\n",
    "        bounds[2] += buffer\n",
    "        bounds[3] += buffer\n",
    "        \n",
    "    s3_client = session.client('s3',**get_aws_creds())\n",
    "    available_files = find_available_files(s3_client, bounds, start_date, end_date, bands)\n",
    "    creds = get_aws_creds()\n",
    "    \n",
    "    \n",
    "    total_data = 0\n",
    "    args = []\n",
    "    contents = s3_client.list_objects_v2(Bucket = s3_bucket_name,Prefix=s3_bucket_prefix)[\"Contents\"]\n",
    "    s3_files = [content['Key'].split(\"/\")[1].replace(\"_\", \"/\").replace(\"MSK/CLOUDS/\",\"MSK_CLOUDS_\") for content in contents] \n",
    "    for file_info in available_files:\n",
    "        if(file_info[0].split(\"tiles/\")[1] not in s3_files):\n",
    "            file_path = file_info[0]\n",
    "            if '/preview/' in file_path:\n",
    "                continue\n",
    "            new_file_path = file_path.replace('_qi_', '').replace('/', '_').replace('tiles_', '')\n",
    "            created_file_path = os.path.join(\"\", new_file_path)\n",
    "\n",
    "            if os.path.exists(created_file_path):\n",
    "                continue\n",
    "\n",
    "            total_data += file_info[1]\n",
    "\n",
    "            args.append(Namespace(available_file=file_path, bucket_name=SENTINEL_2_BUCKET_NAME, profile_name=session.profile_name,\n",
    "                                  dest=created_file_path,aws_access_key_id=creds['aws_access_key_id'],aws_secret_access_key=creds['aws_secret_access_key'],aws_session_token=creds['aws_session_token']))\n",
    "            # creds = get_aws_creds()\n",
    "            # args.append(creds)\n",
    "            # print(args[0])\n",
    "\n",
    "    total_data /= 1E9\n",
    "    print(f'Found {len(args)} files for download. Total size of files is'\n",
    "          f' {round(total_data, 2)}GB and estimated cost will be ${round(0.09 * total_data, 2)}'\n",
    "          )\n",
    "    \n",
    "    # For multiprocessing when being run in iPython (Jupyter notebook, etc.)\n",
    "    # print(args[0])\n",
    "    with mp.Pool(mp.cpu_count() - 1) as pool:\n",
    "        for _ in tqdm.tqdm(pool.imap_unordered(download_task, args), total=len(args)):\n",
    "            pass\n",
    "    \n",
    "    # for arg in tqdm.tqdm(args, total=len(args)):\n",
    "    #     download_task(arg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the start date and end date\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    __spec__ = None\n",
    "    california_bounds = [-120.708008, 33.156797, -113.975687 , 38.395343]\n",
    "\n",
    "    download(session=session, bounds=california_bounds, start_date=datetime(2024, 9, 1),\n",
    "         end_date=datetime(2024, 9, 31), bands=['B02', 'B03', 'B04','B05', 'B06', 'B07','B08', 'B11',\"B12\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
