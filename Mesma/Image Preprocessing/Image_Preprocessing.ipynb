{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "T-AxEer5XNjA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-AxEer5XNjA",
    "outputId": "b549d205-8ebe-4a6a-af98-bb98458f6d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.9.0\n",
      "  latest version: 24.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.11.1\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install these packages before running the code\n",
    "\n",
    "# !conda install -c conda-forge gdal -y\n",
    "# !conda install rasterio\n",
    "# !conda install boto3\n",
    "# !conda install botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6da2ce6a-f70f-46d1-a1c8-689dd3dfd98c",
   "metadata": {
    "id": "6da2ce6a-f70f-46d1-a1c8-689dd3dfd98c"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/opt/conda/envs/preprocessing/lib/python3.10/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /opt/conda/envs/preprocessing/lib/python3.10/site-packages/rasterio/../../../libgdal.so.36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mask\n",
      "File \u001b[0;32m/opt/conda/envs/preprocessing/lib/python3.10/site-packages/rasterio/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mand\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(p, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgdal*.dll\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     23\u001b[0m                     os\u001b[38;5;241m.\u001b[39madd_dll_directory(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(p))\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetBase\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Statistics\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_vsiopener\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _opener_registration\n",
      "\u001b[0;31mImportError\u001b[0m: /opt/conda/envs/preprocessing/lib/python3.10/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /opt/conda/envs/preprocessing/lib/python3.10/site-packages/rasterio/../../../libgdal.so.36)"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import boto3\n",
    "import botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "vymJZVV8I8kB",
   "metadata": {
    "id": "vymJZVV8I8kB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data-store/iplant/home/dakshasinghal/download_and_preprocessing\n",
      "/data-store/iplant/home/dakshasinghal/download_and_preprocessing/input_dir\n",
      "Folder '/data-store/iplant/home/dakshasinghal/download_and_preprocessing/input_dir' created.\n",
      "/data-store/iplant/home/dakshasinghal/download_and_preprocessing/output_dir\n",
      "Folder '/data-store/iplant/home/dakshasinghal/download_and_preprocessing/output_dir' created.\n"
     ]
    }
   ],
   "source": [
    "SCE_folder = \"/\"\n",
    "input_folder_name = \"input_dir\"\n",
    "output_folder_name = \"output_dir\"\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "def create_folder(folder_name):\n",
    "    folder_path = os.path.join(current_dir, folder_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\")\n",
    "\n",
    "create_folder(input_folder_name)\n",
    "create_folder(output_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0m6eEGa70ZNR",
   "metadata": {
    "id": "0m6eEGa70ZNR"
   },
   "outputs": [],
   "source": [
    "# update the temporary credentials\n",
    "def get_aws_creds():\n",
    " return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6Qo48QXjYi",
   "metadata": {
    "id": "5a6Qo48QXjYi"
   },
   "outputs": [],
   "source": [
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    print(\"Upload\", file_name, \"to s3 bucket\" )\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3',**get_aws_creds())\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def delete_files(files):\n",
    "  print(files)\n",
    "  for file in files:\n",
    "    if(os.path.isfile(file)):\n",
    "      os.remove(file)\n",
    "\n",
    "\n",
    "def download_from_s3(s3_client, bucket, file, download_dest):\n",
    "  s3_client.download_file(bucket, file, download_dest)\n",
    "\n",
    "\n",
    "def get_s3_files(s3, bucket, prefix):\n",
    "  paginator = s3.get_paginator('list_objects_v2')\n",
    "  pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "  files = []\n",
    "  for page in pages:\n",
    "      for i in page['Contents']:\n",
    "        if i['Key']!= prefix+\"/\":\n",
    "          files.append(i['Key'].split(\"/\")[1])\n",
    "  return files\n",
    "\n",
    "\n",
    "def grouping_files(files_list):\n",
    "  groups = defaultdict(list)\n",
    "\n",
    "  for file in files_list:\n",
    "      key = \"\".join(file.split(\"_\")[0:6])\n",
    "      groups[key].append(file)\n",
    "\n",
    "  grouped_strings = list(groups.values())\n",
    "\n",
    "  return grouped_strings\n",
    "\n",
    "def resample_bands(resampling_dir):\n",
    "  print(\"Resampling Bands\")\n",
    "  bands_to_resample = [\"B05\", \"B06\", \"B07\",\"B11\",\"B12\"]\n",
    "  files_list = os.listdir(resampling_dir)\n",
    "  for file in files_list:\n",
    "    band = file.split(\"_\")[-1].split(\".\")[0]\n",
    "    if(band in bands_to_resample and \".jp2\" in file):\n",
    "      file_path  = resampling_dir + file\n",
    "      gdal.Warp(file_path, file_path, xRes=10, yRes=10)\n",
    "\n",
    "def read_jp2(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read(1)  # Read the first band\n",
    "        profile = src.profile\n",
    "    return image, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kNoVk8OIlcV_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kNoVk8OIlcV_",
    "outputId": "46130929-87a0-40d1-90c3-5022bb59b292"
   },
   "outputs": [],
   "source": [
    "def apply_detfoo_mask(spectral_band, detfoo_mask):\n",
    "    masked_band = np.where(detfoo_mask != 1, spectral_band, np.nan)  # Masking with NaN\n",
    "    return masked_band\n",
    "\n",
    "def mask_clouds_and_stack_bands(band_files, detfoo_files, output_file):\n",
    "    print(\"Masking Clouds and Stacking Bands\")\n",
    "\n",
    "    masked_arrays = {}\n",
    "    for band_file in band_files:\n",
    "        directory, file_name = band_file.rsplit('/', 1)\n",
    "        base_name, band = file_name.rsplit('_', 1)\n",
    "        detfoo_file = \"/content/drive/MyDrive/Earth Lab/Dry mapping/input_dir/\"+f\"{base_name}_qi_MSK_DETFOO_{band.replace('.jp2', '.gml')}\"\n",
    "        gdf = gpd.read_file(detfoo_file)\n",
    "        with rasterio.open(band_file, driver = \"JP2OpenJPEG\") as src:\n",
    "            band_crs = src.crs\n",
    "            width = src.width\n",
    "            height = src.height\n",
    "            out_image, out_transform = mask(src, gdf.geometry, invert=True, all_touched=True, nodata=src.nodata, crop=False)\n",
    "            print(gdf.geometry)\n",
    "            band_num = int(band_file.split(\".\")[0][-2:])\n",
    "            masked_arrays[band_num] = out_image\n",
    "            print(masked_arrays[band_num])\n",
    "    masked_image = rasterio.open(output_file, 'w', driver = \"Gtiff\", count=len(band_files), crs = band_crs, transform = out_transform, width = width, height = height, dtype = masked_arrays[2].dtype)\n",
    "    index = 1\n",
    "    for key in masked_arrays:\n",
    "      masked_image.write(masked_arrays[key][0], indexes=index)\n",
    "      index+=1\n",
    "\n",
    "    masked_image.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  s3_bucket = \"sce.sentinel2\"  # Update the AWS bucket\n",
    "  s3_input_folder = \"2021_input_dir\" # update the AWS bucket input folder containing the downloaded the sentinel images\n",
    "  drive_input_dir = SCE_folder + \"input_dir/\" \n",
    "  drive_output_dir = SCE_folder + \"output_dir/\" \n",
    "  s3_output_folder = \"2021_output_dir\" # update the AWS bucket folder containing the downloaded the sentinel images\n",
    "  session = boto3.Session()\n",
    "  client_config = botocore.config.Config(max_pool_connections=50)\n",
    "  s3_client = session.client('s3',**get_aws_creds(), config=client_config)\n",
    "  try:\n",
    "    s3_output_contents = s3_client.list_objects_v2(Bucket = s3_bucket,Prefix=s3_output_folder)[\"Contents\"]\n",
    "    s3_output_files = [content['Key'].split(\"/\")[1].replace(\" \", \"\") for content in s3_output_contents]\n",
    "  except:\n",
    "    s3_output_files = []\n",
    "\n",
    "  image_file_names = get_s3_files(s3_client, s3_bucket, s3_input_folder)\n",
    "\n",
    "  group_files = grouping_files(image_file_names)\n",
    "\n",
    "  error_files = []\n",
    "\n",
    "  print(\"Number of Files to be processed:\",len(group_files))\n",
    "\n",
    "  def preprocess_images(files):\n",
    "    band_file_regex_pattern= r\"^\\d{2}_[A-Za-z]_[A-Za-z]{2}_\\d{4}_\\d{1,2}_\\d{1,2}_\\d{1,2}_B(?!01|09|10)\\d{1,2}\\.jp2$\"\n",
    "    band_files = [item for item in files if re.match(band_file_regex_pattern, item)]\n",
    "    detfoo_files = [i for i in files if \"DETFOO\" in i]\n",
    "    qualit_files = [i for i in files if \"QUALIT\" in i]\n",
    "    output_file = \"_\".join(band_files[0].split(\"_\")[0:6]) + \".tif\"\n",
    "    # if(output_file in s3_output_files or output_file in error_files or len(band_files)!=9 or (\"_6_5_\" not in output_file and \"_6_18\" not in output_file)):\n",
    "    if(output_file in s3_output_files or output_file in error_files or len(band_files)!=9 or \"KU_2021\" not in output_file):\n",
    "      return\n",
    "    # delete_all_files_from_trash()\n",
    "\n",
    "\n",
    "    band_files_path = [drive_input_dir + i for i in band_files]\n",
    "    deftoo_files_path = [drive_input_dir + i for i in detfoo_files]\n",
    "    qualit_files_path = [drive_input_dir + i for i in qualit_files]\n",
    "    full_output_file = \"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "      for index in range(len(band_files)):\n",
    "        download_from_s3(s3_client, s3_bucket, s3_input_folder+\"/\"+band_files[index], band_files_path[index])\n",
    "\n",
    "      for index in range(len(detfoo_files)):\n",
    "        download_from_s3(s3_client, s3_bucket, s3_input_folder+\"/\"+detfoo_files[index], deftoo_files_path[index])\n",
    "\n",
    "      output_file = \"_\".join(band_files[0].split(\"_\")[0:6]) + \".tif\"\n",
    "\n",
    "      print(\"Processing: \", output_file)\n",
    "\n",
    "      full_output_file = drive_output_dir + output_file\n",
    "\n",
    "\n",
    "      resample_bands(drive_input_dir)\n",
    "      mask_clouds_and_stack_bands(band_files_path, deftoo_files_path, full_output_file)\n",
    "      upload_file(full_output_file,s3_bucket, s3_output_folder+'/ {}'.format(output_file))\n",
    "\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      error_files.append(output_file)\n",
    "\n",
    "    files_to_be_deleted = band_files_path + deftoo_files_path + qualit_files_path\n",
    "    files_to_be_deleted = band_files_path + deftoo_files_path + qualit_files_path\n",
    "    files_to_be_deleted.append(full_output_file)\n",
    "    delete_files(files_to_be_deleted)\n",
    "\n",
    "  for files in reversed(group_files):\n",
    "    if (len(files)==0 or files[0]==\"\"):\n",
    "      continue\n",
    "    preprocess_images(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227e0ca-f4e5-462d-be81-f21d2c10f5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "cell_execution_strategy": "setup",
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
